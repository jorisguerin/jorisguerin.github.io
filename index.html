<!DOCTYPE html>
<html>

<head>
	<meta name=viewport content="width=device-width, initial-scale=1">
	<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

	<title>Joris Guérin</title>

	<link rel="icon" type="image/jpg" href="images/icon.jpeg">
	<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	<link href="styles/style.css" rel="stylesheet">

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
</head>

<body>
<table width="860" border="0" align="center" cellspacing="0" cellpadding="0">
<tr>
<td>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tr>
			<td width="90%" valign="middle">
				<p align="center">
					<name>Joris Guérin</name>
				</p>
				<p align=center>
          <a href="mailto:jorisguerin<dot>research<at>gmail<dot>com">Email</a> &nbsp/&nbsp
          <a href="CV.pdf">CV</a> &nbsp/&nbsp
          <a href="https://github.com/jorisguerin">Github</a> &nbsp/&nbsp
          <a href="https://scholar.google.fr/citations?user=gO-31VYAAAAJ&hl=fr&authuser=1&oi=sra">Scholar</a> &nbsp/&nbsp
          <!--<a href="https://twitter.com/jorisguerin/">Twitter</a> &nbsp/&nbsp-->
					<a href="documents/thesis.pdf">Dissertation</a>
        </p>
				<p align="center">
					<br>
					Post-doctoral researcher at <a href="http://www.uff.br/">Universidade Federal Fluminense</a> - <a href="http://www.ic.uff.br/">Instituto de Computação</a>.
				</p>
			</td>
			<td width="10%">
				<img src="images/joris.png" style="float:right;width:200px;height:200px">
			</td>
		</tr>
	</table>

	<p align="justify">
		I received a Ph.D. in computer science and signal processing in 2018, from Arts et Métiers ParisTech, Lille, France. Before that, I received the diplôme d'ingénieur (equivalent to M.Sc. degree) from Arts et Métiers ParisTech and the M.Sc. in Industrial Engineering from Texas Tech University, both in 2015. I am currently a postdoctoral researcher at Universidade Federal Fluminense, and a research engineer at Isabo.ai. My research interest includes Reinforcement Learning for real robotics systems, Unsupervised sorting of real world objects, deep ensemble methods for Image Clustering, object detection from synthetic images and person re-identification.
	</p>
	<br/>
	<div class="page_selector">
	<table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
	<tr>
			<td id="home">Home</td>
			<td id="publications">Publications</td>
			<td id="teaching">Teaching</td>
			<td id="videos">Videos</td>
			<td id="blog">Blog articles</td>
	</tr>
	</table>
  </div>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<tbody>
	<tr>
		<td width="100%" valign="middle">
			<div class="content">
			<h2>News</h2>
			<ul>
				<li>
				December 2019: My Ph.D. thesis entitled <i> Machine learning improvements for robotic applications in
						industrial context: Case study of autonomous sorting </i> is now available for download.
				</li>
				<li>
				February 2019: I started a postdoc at UFF under supervision of profs <a href="http://www.ic.uff.br/index.php/pessoas/168-docente?docente=22">Esteban Clua</a> and <a href="http://www.ic.uff.br/index.php/pt/pessoas/168-docente?docente=36">José Viterbo</a>.
				</li>
				<li>
				February 2019: Started to work as a research engineer at <a href="https://www.isabo.ai/en/home/">Isabo.ai</a>.
				</li>
				<li>
				December 2018: My defense went well and my Ph.D. thesis has been proposed for the	<b>Prix Bézier 2018</b>.
				</li>
				<li>
				July 2018: Our paper <i>Improving Image Clustering With Multiple Pretrained CNN Feature Extractors</i> has been accepted at BMVC 2018.
				</li>
				<li>
				June 2018: Our paper <i>Semantically Meaningful View Selection</i> has been accepted at IROS 2018.
				</li>
			</ul>
			<br>
			<h2>Relevant publications</h2>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/thesis.png" alt="Very good image summarizing the paper" width="200"></td>
			<td width="75%" valign="top">
			<p align="justify">
			<b><papertitle>Machine learning improvements for robotic applications in industrial context:
						Case study of autonomous sorting</papertitle></b>
			<br>
			Joris Guérin
			<br>
			<em>Ph.D. dissertation</em> (2018)
			<br>
			[<a href="documents/thesis.pdf">PDF</a>]
			[<a href="./bib/thesis.txt">bibtex</a>]
			[<a href="./presentations/pres_defense.pdf">presentation</a>]
			<br><br>
			Thanks to their flexible mechanical design, modern industrial robots can be programmed
			for different tasks without physical modification. In addition, they are highly
			instrumented and should be able to be responsive to their environment. However,
			the use of robots in industry is still restricted to repeatable tasks with low level
			of adaptability. In an industrial context, it is essential to program robots that can
			autonomously adapt to different applications and are robust to changes in working
			conditions. The machine learning framework for robot programming is well suited to
			design such kinds of adaptive and robust applications. Hence, in this thesis, several
			machine learning contributions are presented, aiming at designing smarter robotic
			applications, with a broader operational range. The methods developed are centered on
			autonomous sorting, but may be useful to address problems in many other subfields
			of robotics. Throughout this thesis, we propose new approaches to image clustering,
			optimal view selection, trajectory learning and stereo localization, with the objective
			of designing more universal robotic sorting applications.
			</p>
			</td></tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/bmvc18.png" alt="Very good image summarizing the paper" width="200"></td>
			<td width="75%" valign="top">
			<p align="justify">
			<b><papertitle>Improving Image Clustering With Multiple Pretrained CNN Feature Extractors</papertitle></b>
			<br>
			Joris Guérin, <a href="https://homes.cs.washington.edu/~bboots/">Byron Boots</a>
			<br>
			<em>British Machine Vision Conference (BMVC)</em>, 2018
			<br>
			[<a href="http://bmvc2018.org/contents/papers/0071.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/1807.07760">arXiv</a>]
			[<a href="./bib/bmvc18.txt">bibtex</a>]
			[<a href="./presentations/poster_bmvc18.pdf">poster</a>]
			<br><br>
			For many image clustering problems, replacing raw image data with features extracted by a
			pretrained convolutional neural network (CNN), leads to better clustering performance.
			However, the specific features extracted, and, by extension, the selected CNN architecture,
			can have a major impact on the clustering results. In practice, this crucial design choice
			is often decided arbitrarily due to the impossibility of using cross-validation with
			unsupervised learning problems. However, information contained in the different pretrained
			CNN architectures may be complementary, even when pretrained on the same data. To improve
			clustering performance, we rephrase the image clustering problem as a multi-view clustering (MVC)
			problem that considers multiple different pretrained feature extractors as different "views" of
			the same data. We then propose a multi-input neural network architecture that is trained
			end-to-end to solve the MVC problem effectively. Our experimental results, conducted on three
			different natural image datasets, show that: 1. using multiple pretrained CNNs jointly as feature
			extractors improves image clustering; 2. using an end-to-end approach improves MVC; and
			3. combining both produces state-of-the-art results for the problem of image clustering.
			</p>
			</td></tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/iros18.png" alt="Very good image summarizing the paper" width="200"></td>
			<td width="75%" valign="top">
			<p align="justify"><b><papertitle>Semantically Meaningful View Selection</papertitle></b>
			<br>
			Joris Guérin,
			<a href="http://www.oliviergibaru.org/">Olivier Gibaru</a>,
			<a href="https://www.researchgate.net/profile/Eric_Nyiri">Éric Nyiri</a>,
			<a href="https://www.researchgate.net/profile/Thiery_Stephane">Stéphane Thiery</a>,
			<a href="https://homes.cs.washington.edu/~bboots/">Byron Boots</a>
			<br>
			<em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2018
			<br>
			[<a href="https://arxiv.org/pdf/1807.10303.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/1807.10303">arXiv</a>]
			[<a href="./bib/iros18.txt">bibtex</a>]
			[<a href="./presentations/pres_iros18.pdf">presentation</a>]
			[<a href="https://github.com/jorisguerin/SemanticViewSelection_dataset">data</a>]
			<br><br>
			An understanding of the nature of objects could help robots to solve both
			high-level abstract tasks and improve performance at lower-level concrete tasks.
			Although deep learning has facilitated progress in image understanding, a robot's
			performance in problems like object recognition often depends on the angle
			from which the object is observed. Traditionally, robot sorting tasks rely on
			fixed top-down views of the objects. By changing its viewing angle, a robot
			can select a more semantically informative view leading to better performance
			for object recognition. In this paper, we introduce the problem of semantic
			view selection, which consists in finding good camera poses to gain semantic
			knowledge about observed objects. We propose a conceptual generic formulation
			of the problem, together with a relaxation based on clustering, to make it
			solvable. We then present a new image dataset consisting of around 10k images
			representing various views of 144 objects under different poses. Finally we use
			this dataset to propose a first solution to the problem by training a neural
			network to predict a ``semantic score'' from a top view image and camera pose.
			The views predicted to have higher scores are then showed to provide better
			clustering results than fixed top-down views.
			</p>
			</td></tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tr>
			<td width="25%" valign="top">
				<img src="images/iecon16.png" alt="Very good image summarizing the paper" width="200"></td>
			<td width="75%" valign="top">
			<p align="justify"><b><papertitle>Learning local trajectories for high precision robotic tasks :
				application to KUKA LBR iiwa Cartesian positioning</papertitle></b>
			<br>
			Joris Guérin,
			<a href="http://www.oliviergibaru.org/">Olivier Gibaru</a>,
			<a href="https://www.researchgate.net/profile/Eric_Nyiri">Éric Nyiri</a>,
			<a href="https://www.researchgate.net/profile/Thiery_Stephane">Stéphane Thiery</a>
			<br>
			<em>IECON</em> 2016
			<br>
			[<a href="https://arxiv.org/pdf/1701.01497.pdf">PDF</a>]
			[<a href="https://arxiv.org/abs/1701.01497">arXiv</a>]
			[<a href="./bib/iecon16.txt">bibtex</a>]
			[<a href="./presentations/pres_iecon16.pdf">presentation</a>]
			[<a href="https://www.youtube.com/watch?v=Ekda9q3vv6Y">video</a>]
			<br><br>
			To ease the development of robot learning in industry, two conditions need
			to be fulfilled. Manipulators must be able to learn high accuracy and precision
			tasks while being safe for workers in the factory. In this paper, we extend
			our <a href="https://iopscience.iop.org/article/10.1088/1742-6596/783/1/012036/pdf">previous paper</a>,
			which consist in rapid learning of local high accuracy behaviors. By exploration and regression,
			linear and quadratic models are learnt for respectively the dynamics and cost function.
			Iterative Linear Quadratic Gaussian Regulator combined with cost quadratic regression
			can converge rapidly in the final stages towards high accuracy behavior as the cost
			function is modelled quite precisely. In this paper, both a different cost function
			and a second order improvement method are implemented within this framework. We also
			propose an analysis of the algorithm parameters through simulation for a positioning task.
			Finally, an experimental validation on a KUKA LBR iiwa robot is carried out. This collaborative
			robot manipulator can be easily programmed into safety mode, which makes it qualified for the
			second industry constraint stated above.
			</p>
			</td></tr>
			</table>

			</div>
		</td>
	</tr>
	</tbody>
	</table>



	<!--Thanks-->
	<br>
  <p align="right">
    <font size="2">
      <a href="https://jonbarron.info">Awesome webpage...</a>
    </font>
  </p>
</td>
</tr>
</table>

<script src="scripts/publications.js"></script>
<script src="scripts/teaching.js"></script>
<script src="scripts/home.js"></script>

</body>
</html>
